---
output:
  pdf_document: default
  html_document: default
---
Work Out Data Machine Learning Project
----------------------------------------------------
The goal of our machine learning project to create a model that can accurately predict what class of working out an individual is in. To do this we are suppose to use machine learning functions and princicpals to make the optimal model for predicting. 
## Background
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

## Loading and Cleaning the Data
First,lets download the data from the links below
```{r}
train_url <- download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "training_dat.csv")
test_url <- download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "testing_dat.csv")
```
Now, let's load the data and write the 'na.strings' argument in so that we change confounding null and na values in as NA so that we may get rid of them.
```{r}
training <- read.csv("training_dat.csv", header = TRUE, na.strings=c("NA", "#DIV/0!",""))
testing <- read.csv("testing_dat.csv", header = TRUE, na.strings=c("NA", "#DIV/0!",""))
```
Next, let's change the column sum of the na values into 0 so that we can eliminate NA values.
```{r}
training <-  training[,colSums(is.na(training)) == 0]
testing <-  testing[,colSums(is.na(training)) == 0]
```
 After that, let's remove the first seven columns since they hold data types that will complicate the model. 
```{r}
training <- training[,-c(1:7)]
testing <- testing [,-c(1:7)]
```
## Data Partioning and Model Building
Next, we will download and implement the 'caret' package to split the cleaned data into training and testing sets. These are the sets we will use to run the model. 
```{r}
library(caret)
inTrain <- createDataPartition(training$classe, p = 0.6, list = FALSE)
train <- training[inTrain,]
test <- training[-inTrain,]
```
Last, let's remove the data not characterized by a near zero variance in both the training and testing set using the 'nearZeroVar' function from the caret package.
```{r}
nearZero <- nearZeroVar(train, saveMetrics=TRUE)
train <- train[!nearZero$nzv,]
nearZeroTest <- nearZeroVar(test, saveMetrics = TRUE)
test <- test[!nearZeroTest$nzv,]
```
Now that we have our data split we can create our models
### create models 
We are going to use the rpart model to create our model. Using the 'rpart.plot' function in the 'rpart.plot' package, we can create a decision tree that will tell us how the model was created.
```{r r part-model}
library(rpart); library(rpart.plot)
model1 <- rpart(classe~., data = train, method = "class")
rpart.plot(model1, main = "Classification", extra = 102, under = TRUE,faclen=0)
```
now that we have our model lets make predictions using the model and the test data and see how accurate the model is at predicting using confusion matrix
```{r rpart-model-accuracy}
pred1 <- predict(model1, test, type = "class")
confusionMatrix(pred1, test$classe)
```
as we can see from the confusion matrix there is very low accuracy in the model.
Lucky for us we can us the 'randomForest' to create a bunch of models for us and choose the best one based on the outputs. 
### prediction w/ random forest 
```{r randomForest-model}
library("randomForest")
model2 <- randomForest(classe~., data = train, method = "class")
```
Now that we have our model let's predict to see how accurate it is.
```{r final-model}
pred2 <- predict(model2, test)
confusionMatrix(pred2, test$classe)
```
As we can see this model is extremley and accurate thanks to the random forest model. This model will be the model that we use in the future to predict the workout class of new observations.